{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train = np.expand_dims(X_train, axis=-1) # <--- add batch axis\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "\n",
    "x_train, x_test = X_train.reshape(-1,28,28,1), X_test.reshape(-1,28,28,1)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '5')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.imshow(X_train[0])\n",
    "plt.xlabel(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 93s 49ms/step - loss: 0.1788 - accuracy: 0.9455\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 86s 46ms/step - loss: 0.0732 - accuracy: 0.9776\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 85s 45ms/step - loss: 0.0478 - accuracy: 0.9848\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 90s 48ms/step - loss: 0.0350 - accuracy: 0.9887\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 89s 48ms/step - loss: 0.0280 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d428a8dc60>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28),),\n",
    "    keras.layers.Dense(2000,activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "ann.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "ann.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 10ms/step - loss: 0.1031 - accuracy: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10307694971561432, 0.9735999703407288]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 159ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(ann.predict(X_test[:1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.98      0.98      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.98      0.96      0.97       982\n",
      "           5       0.94      0.99      0.96       892\n",
      "           6       0.99      0.95      0.97       958\n",
      "           7       0.99      0.97      0.98      1028\n",
      "           8       0.99      0.94      0.97       974\n",
      "           9       0.94      0.99      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_values = ann.predict(X_test)\n",
    "y_pred_class = [np.argmax(element) for element in y_pred_values]\n",
    "\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 77s 40ms/step - loss: 0.1658 - accuracy: 0.9502\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.0555 - accuracy: 0.9830\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 76s 40ms/step - loss: 0.0399 - accuracy: 0.9874\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 78s 42ms/step - loss: 0.0304 - accuracy: 0.9904\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 80s 42ms/step - loss: 0.0243 - accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d440773790>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = keras.Sequential([\n",
    "   \n",
    "    # convolution + Relu\n",
    "     keras.layers.Conv2D(filters=50, kernel_size=(3,3) ,activation='relu', input_shape=(28,28,1)),\n",
    "    # Max Pooling\n",
    "     keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # convolution + Relu\n",
    "     keras.layers.Conv2D(filters=20, kernel_size=(3,3) ,activation='relu'),\n",
    "    # Max Pooling\n",
    "     keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "   \n",
    "\n",
    "    #dense\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(60,activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0296 - accuracy: 0.9906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02963307499885559, 0.9905999898910522]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      0.99      0.99      1010\n",
      "           4       0.99      1.00      0.99       982\n",
      "           5       0.98      0.99      0.99       892\n",
      "           6       1.00      0.98      0.99       958\n",
      "           7       0.99      0.99      0.99      1028\n",
      "           8       0.98      1.00      0.99       974\n",
      "           9       1.00      0.98      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_values = cnn.predict(X_test)\n",
    "y_pred_class = [np.argmax(element) for element in y_pred_values]\n",
    "\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
